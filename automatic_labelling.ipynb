{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34cbdfc5-27dd-4c1e-90f2-0ffeec29f7cd",
   "metadata": {},
   "source": [
    "# Single image analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1035e415-134e-4fff-a264-8c357b2755cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09f570ae-c98f-4b46-a76f-252fde5c44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_window(frame):\n",
    "    frame = cv.resize(frame,(frame.shape[0]//3,frame.shape[1]//3))\n",
    "    return frame\n",
    "\n",
    "def extract_pit_contours(frame):\n",
    "    \"\"\" Detect and calculate area for each pit. Thresh old of minimum detection is set to 100 pixel.\n",
    "    return, the image with each pit highlighted in green with its bonding box. Also returns, it coordinates and the\n",
    "    area calculated at each frame.\n",
    "        => Allows the seperation between pits having a growing area (stable) and pits that have a stable area (unstable)\n",
    "    \"\"\"\n",
    "    gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "    blur = cv.GaussianBlur(gray,(3,3),0)\n",
    "    _, thresh = cv.threshold(blur, 80, 255, cv.THRESH_BINARY)\n",
    "    kernel = np.ones((21,21),np.uint8)\n",
    "    opening = cv.morphologyEx(thresh, cv.MORPH_OPEN, kernel)\n",
    "    equ = cv.equalizeHist(blur)\n",
    "\n",
    "\n",
    "    contours,_ = cv.findContours(opening, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    pit_roi = []\n",
    "    areas= []\n",
    "    for cnt in contours:\n",
    "        area = cv.contourArea(cnt)\n",
    "        if 1000000 > area >= 100: \n",
    "            cv.drawContours(frame,[cnt],-1,(0,255,0),2)\n",
    "            x,y,w,h = cv.boundingRect(cnt)\n",
    "            pit_roi.append((x,y,w,h))\n",
    "            areas.append(area)\n",
    "            cv.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv.putText(frame,f\"{area:.0f}\",(x,y-30),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX,2,(0,255,0),3)\n",
    "\n",
    "\n",
    "    cv.imshow(\"image\", resize_to_window(frame))\n",
    "    return frame, pit_roi, areas\n",
    "\n",
    "def reference_frame(pits_dict):\n",
    "    \"\"\"\n",
    "    found the reference frame at which all the pits detected during all the video are visible\n",
    "    \"\"\"\n",
    "    ref_frame = None\n",
    "    last_areas = pits_dict[\"area\"][len(pits_dict[\"frame\"])-10]\n",
    "    average_nbr_of_objects = round(np.mean([len(objct) for objct in pits_dict[\"area\"]]))+1\n",
    "    for frame,objct in enumerate(pits_dict[\"area\"]):\n",
    "        if len(objct) == average_nbr_of_objects:\n",
    "            ref_frame = frame\n",
    "            break\n",
    "    return ref_frame\n",
    "\n",
    "def idx_corresponding_pit(ref_rois,end_rois):\n",
    "    \"\"\"\n",
    "    Variables :\n",
    "        -  ref_rois = array corresponding to the rois of the first frame that has a len corresponding to the mean len observed for all frames\n",
    "        -  end_rois = array corresponding to the roi at the end of the \n",
    "    Out put :\n",
    "    Gives an array of the rois and their index on the end_rois corresponding to the pit that where detected at the ref rois\n",
    "\n",
    "    Purpose : \n",
    "    This function is mandatory in order to recover pits from unwanted objects that where detected by the algorythme.\n",
    "    \"\"\"\n",
    "        \n",
    "    idx = []\n",
    "    \n",
    "    for roi_ref in ref_rois:\n",
    "        x_ref = roi_ref[0]\n",
    "        y_ref = roi_ref[1]\n",
    "\n",
    "        delta_x = [np.abs(x_ref-x_end[0]) for x_end in end_rois]\n",
    "        delta_y = [np.abs(x_ref-x_end[1]) for x_end in end_rois]\n",
    "\n",
    "        min_x_idx = np.where(delta_x==np.min(delta_x))\n",
    "        min_y_idx = np.where(delta_y==np.min(delta_y))\n",
    "\n",
    "        if min_y_idx == min_x_idx :\n",
    "            idx.append(min_y_idx)\n",
    "        else :\n",
    "            print(min_x_idx,min_y_idx)\n",
    "\n",
    "    return idx\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "def pit_recognition(video_paths=\"/home/ters-user/Documents/videos/30mM.mp4\"):\n",
    "    \"\"\"\n",
    "    Labelized each pit and associate to it a value between 1 (stable pit) and 2 (unstable pit).\n",
    "    returns a dictionnary storing the each frame with the coordinated of each pit and the size of each bonding box.\n",
    "    Also return the label associated with each detected objects.\n",
    "\n",
    "    INPUT : video_paths of the corrosion video\n",
    "    OUTPUT : frame, (x,y,w,h),area,label with,\n",
    "    \n",
    "         - frame : numpy array corresponding to the image at a particular frame\n",
    "         - (x,y,w,h) : numpy array giving coordinates for each objetcs. (x,y) horizontal and vertical coordinates , (w,h) width and height of the bonding box\n",
    "         - area : numpy array of the same size as (x,y,w,h) with the area of each object\n",
    "         - label : numpy array of the same size as (x,y,w,h) with the label (1: stable pit or  2: unstable pit) for each object\n",
    "    \"\"\"\n",
    "    cap = cv.VideoCapture(video_paths)\n",
    "    \n",
    "    pit_coordinates = {\"frame\":[],\"(x,y,w,h)\":[],\"area\":[],\"label\":[]}\n",
    "    frame_number = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_number += 1\n",
    "    \n",
    "        displayed_img = frame.copy()\n",
    "        img,roi,area = extract_pit_contours(displayed_img)\n",
    "        pit_coordinates[\"frame\"].append(frame)\n",
    "        pit_coordinates[\"(x,y,w,h)\"].append(roi[-1:]+roi[:-1])\n",
    "        pit_coordinates[\"area\"].append(area)\n",
    "    \n",
    "        key = cv.waitKey(25) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    \n",
    "    \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    average_nbr_of_objects = round(np.mean([len(objct) for objct in pit_coordinates[\"area\"]]))+1    \n",
    "    ref_array = pit_coordinates[\"area\"][reference_frame(pit_coordinates)]\n",
    "    last_areas = None\n",
    "    last_areas_frame = None\n",
    "    for frame, areas in enumerate(pit_coordinates[\"area\"][::-1]):\n",
    "        if len(areas) == len(ref_array):\n",
    "            last_areas = areas\n",
    "            last_areas_frame = len(pit_coordinates[\"area\"])- frame\n",
    "            break\n",
    "    for frame,objct in enumerate(pit_coordinates[\"area\"]):\n",
    "        labels = np.zeros_like(ref_array)\n",
    "        # objct = [objct[idx] for idx in idx_corresponding_pit(pit_coordinates[\"(x,y,w,h)\"][reference_frame(pit_coordinates)]\n",
    "        #                                                      ,pit_coordinates[\"(x,y,w,h)\"][len(pit_coordinates[\"frame\"])-10])]\n",
    "\n",
    "        if len(objct)==len(ref_array):\n",
    "            for i,area in enumerate(objct):\n",
    "                if np.abs(pit_coordinates[\"area\"][reference_frame(pit_coordinates)][i] - last_areas[i]) > 3000:\n",
    "                    labels[i] = 1.0\n",
    "                else :\n",
    "                    labels[i] = 2.0\n",
    "\n",
    "        pit_coordinates[\"label\"].append(labels)\n",
    "\n",
    "    labeled_img = pit_coordinates['frame'][len(pit_coordinates[\"frame\"])-10]\n",
    "    \n",
    "    print(f\"{pit_coordinates['(x,y,w,h)'][reference_frame(pit_coordinates)]} \\n {pit_coordinates[\"label\"][last_areas_frame-1]}\\n {pit_coordinates[\"area\"][last_areas_frame-1]}\\n\\n\")\n",
    "    \n",
    "    for roi,label in zip(pit_coordinates['(x,y,w,h)'][reference_frame(pit_coordinates)],pit_coordinates[\"label\"][last_areas_frame-1]):\n",
    "        x,y = roi[0],roi[1]\n",
    "        if label == 1:\n",
    "            cv.putText(labeled_img,\"STABLE\",(x,y),cv.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "        elif label ==2:\n",
    "            cv.putText(labeled_img,\"UNSTABLE\",(x,y),cv.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    \n",
    "    cv.imshow(\"labeled_img\",resize_to_window(labeled_img))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c36790-0ed3-449a-8fa4-32bbfa97d070",
   "metadata": {},
   "source": [
    "# Video analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae600c25-5bb6-4228-b8ac-9ef1d5c2485e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1995, 423, 13, 13), (1442, 1957, 18, 18), (1044, 1894, 20, 24), (904, 1594, 40, 36), (1873, 1173, 14, 16), (115, 1105, 90, 90), (95, 952, 14, 16), (1823, 754, 14, 13), (1938, 705, 62, 68), (2143, 521, 13, 13), (1927, 450, 24, 23)] \n",
      " [2. 2. 2. 2. 1. 2. 2. 1. 2. 2. 2.]\n",
      " [238.5, 315.5, 1034.0, 150.5, 9749.5, 151.0, 119.5, 6579.5, 114.0, 355.0, 114.0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pit_recognition(\"/home/ters-user/Documents/videos/30mM.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab7d17-4756-4232-a016-531533168952",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9a4e5ff-3d91-4c6c-91c8-f5431a8b46b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3, 2]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste = [2,3,4,5]\n",
    "liste[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9b4da-b325-49fe-924c-423146821a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
